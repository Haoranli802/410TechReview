{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "mpKYpayxkvhq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load email data from emails.csv\n",
        "data = pd.read_csv('sample_data/emails.csv')\n",
        "X_text = data['text']\n",
        "y = data['spam'].values.astype(np.float32)\n",
        "\n",
        "# Convert text data to TF-IDF features\n",
        "vectorizer = TfidfVectorizer(max_features=100)\n",
        "X = vectorizer.fit_transform(X_text).toarray().astype(np.float32)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 100\n",
        "hidden_size = 50\n",
        "output_size = 1\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "# PyTorch Model\n",
        "class PyTorchModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PyTorchModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "# TensorFlow Model\n",
        "tf_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(hidden_size, activation='relu', input_shape=(input_size,)),\n",
        "    tf.keras.layers.Dense(output_size, activation='sigmoid')\n",
        "])\n",
        "tf_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# PyTorch Training and Evaluation\n",
        "def train_pytorch_model():\n",
        "    model = PyTorchModel()\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    model.train()\n",
        "    start_time = time.time()\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(0, len(X_train), batch_size):\n",
        "            batch_X = torch.tensor(X_train[i:i+batch_size])\n",
        "            batch_y = torch.tensor(y_train[i:i+batch_size]).float()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y.view(-1, 1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    end_time = time.time()\n",
        "    print(f'PyTorch Training Time: {end_time - start_time:.2f} seconds')\n",
        "\n",
        "    # Evaluate on test set\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_X = torch.tensor(X_test)\n",
        "        test_outputs = model(test_X).numpy()\n",
        "        test_predictions = (test_outputs > 0.5).astype(np.float32)\n",
        "        accuracy = accuracy_score(y_test, test_predictions)\n",
        "        print(f'PyTorch Test Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# TensorFlow Training and Evaluation\n",
        "def train_tensorflow_model():\n",
        "    start_time = time.time()\n",
        "    tf_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "    end_time = time.time()\n",
        "    print(f'TensorFlow Training Time: {end_time - start_time:.2f} seconds')\n",
        "\n",
        "    # Evaluate on test set\n",
        "    test_predictions = (tf_model.predict(X_test) > 0.5).astype(np.float32)\n",
        "    accuracy = accuracy_score(y_test, test_predictions)\n",
        "    print(f'TensorFlow Test Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Compare Training Performance\n",
        "train_pytorch_model()\n",
        "train_tensorflow_model()\n",
        "\n",
        "# Compare Inference Performance\n",
        "sample_input = np.random.randn(1, input_size).astype(np.float32)\n",
        "\n",
        "# PyTorch Inference\n",
        "def pytorch_inference():\n",
        "    model = PyTorchModel()\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        input_tensor = torch.tensor(sample_input)\n",
        "        start_time = time.time()\n",
        "        for _ in range(1000):\n",
        "            output = model(input_tensor)\n",
        "        end_time = time.time()\n",
        "    print(f'PyTorch Inference Time (1000 runs): {end_time - start_time:.2f} seconds')\n",
        "\n",
        "# TensorFlow Inference\n",
        "def tensorflow_inference():\n",
        "    start_time = time.time()\n",
        "    for _ in range(1000):\n",
        "        output = tf_model(sample_input)\n",
        "    end_time = time.time()\n",
        "    print(f'TensorFlow Inference Time (1000 runs): {end_time - start_time:.2f} seconds')\n",
        "\n",
        "# Compare Inference Performance\n",
        "pytorch_inference()\n",
        "tensorflow_inference()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVD9aB44mhF4",
        "outputId": "45e1e637-f570-4daf-a2fa-769e673aa95e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Training Time: 2.25 seconds\n",
            "PyTorch Test Accuracy: 0.96\n",
            "TensorFlow Training Time: 3.99 seconds\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "TensorFlow Test Accuracy: 0.96\n",
            "PyTorch Inference Time (1000 runs): 0.05 seconds\n",
            "TensorFlow Inference Time (1000 runs): 2.41 seconds\n"
          ]
        }
      ]
    }
  ]
}